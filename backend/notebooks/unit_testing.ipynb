{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goldyrana/miniconda3/envs/bounce/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/goldyrana/mess/deep_learning/projects/rag/backend/notebooks\n"
     ]
    }
   ],
   "source": [
    "from backend.src.extractors.data_ingestion import DataIngestion\n",
    "from backend.src.extractors.image_summarizer import ImageSummarizer\n",
    "from backend.src.extractors.text_summarizer import TextSummarizer\n",
    "from backend.src.constants import *\n",
    "from backend.src.config.configuration import ConfigurationManager\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/goldyrana/mess/deep_learning/projects/rag/backend/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/reports/2023_removed/images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:28:44,510 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': [{'type': 'text', 'text': 'Describe the image in detail. Be specific about graphs and numbers'}, {'type': 'image_url', 'image_url': {'url': \"data:image/jpeg;base64,('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', 'data/reports/2023_removed/images/figure-1-1.jpg')\"}}], 'role': 'user'}], 'model': 'gpt-4o', 'stream': False, 'temperature': 0.0}}\n",
      "2025-02-10 17:28:44,553 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-02-10 17:28:44,565 - httpcore.connection - DEBUG - close.started\n",
      "2025-02-10 17:28:44,584 - httpcore.connection - DEBUG - close.complete\n",
      "2025-02-10 17:28:44,593 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-02-10 17:28:44,642 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x326729430>\n",
      "2025-02-10 17:28:44,643 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x326643cc0> server_hostname='api.openai.com' timeout=None\n",
      "2025-02-10 17:28:44,675 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x35ee74ca0>\n",
      "2025-02-10 17:28:44,676 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-10 17:28:44,678 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-10 17:28:44,678 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-10 17:28:44,679 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-10 17:28:44,679 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:28:46,259 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Mon, 10 Feb 2025 11:58:45 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'149'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'19'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-input-images', b'50000'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-input-images', b'49999'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29201'), (b'x-ratelimit-reset-input-images', b'1ms'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.598s'), (b'x-request-id', b'req_9fa46aa8856953b60ee183dea343e047'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90fbeddd38db545e-DEL'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-10 17:28:46,310 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "2025-02-10 17:28:46,327 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-10 17:28:46,331 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-10 17:28:46,332 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-10 17:28:46,333 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-10 17:28:46,335 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"400 Bad Request\" Headers({'date': 'Mon, 10 Feb 2025 11:58:45 GMT', 'content-type': 'application/json', 'content-length': '149', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-gccgvei9eaw4a1hksddpirf5', 'openai-processing-ms': '19', 'openai-version': '2020-10-01', 'x-ratelimit-limit-input-images': '50000', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-input-images': '49999', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '29201', 'x-ratelimit-reset-input-images': '1ms', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '1.598s', 'x-request-id': 'req_9fa46aa8856953b60ee183dea343e047', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90fbeddd38db545e-DEL', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-02-10 17:28:46,336 - openai._base_client - DEBUG - request_id: req_9fa46aa8856953b60ee183dea343e047\n",
      "2025-02-10 17:28:46,337 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/goldyrana/miniconda3/envs/bounce/lib/python3.9/site-packages/openai/_base_client.py\", line 1043, in _request\n",
      "    response.raise_for_status()\n",
      "  File \"/Users/goldyrana/miniconda3/envs/bounce/lib/python3.9/site-packages/httpx/_models.py\", line 829, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400\n",
      "2025-02-10 17:28:46,354 - openai._base_client - DEBUG - Not retrying\n",
      "2025-02-10 17:28:46,356 - openai._base_client - DEBUG - Re-raising status error\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Invalid base64 image_url.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_base64'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images_path:\n\u001b[1;32m     31\u001b[0m     encoded_image \u001b[38;5;241m=\u001b[39m image_summarizer\u001b[38;5;241m.\u001b[39mencode_image(image)\n\u001b[0;32m---> 32\u001b[0m     image_summaries\u001b[38;5;241m.\u001b[39mappend(\u001b[43mimage_summarizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_summarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_image\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m     encoded_images\u001b[38;5;241m.\u001b[39mappend(encoded_image)\n\u001b[1;32m     35\u001b[0m encoded_images, image_summaries \u001b[38;5;241m=\u001b[39m image_summarizer\u001b[38;5;241m.\u001b[39madd_metadata(encoded_images, image_summaries, automatic_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/mess/deep_learning/projects/rag/backend/src/extractors/image_summarizer.py:51\u001b[0m, in \u001b[0;36mImageSummarizer.image_summarize\u001b[0;34m(self, img_base64)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimage_summarize\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_base64) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Summarize image using LLM model API\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m        img_base64: base64 encoded image\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m        prompt: prompt to summarize image\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m        str: summary of image\"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_summary_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata:image/jpeg;base64,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimg_base64\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/miniconda3/envs/bounce/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/envs/bounce/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bounce/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 690\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/bounce/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/bounce/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:790\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 790\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/miniconda3/envs/bounce/lib/python3.9/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bounce/lib/python3.9/site-packages/openai/resources/chat/completions.py:863\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    860\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    861\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bounce/lib/python3.9/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bounce/lib/python3.9/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bounce/lib/python3.9/site-packages/openai/_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1073\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Invalid base64 image_url.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_base64'}}"
     ]
    }
   ],
   "source": [
    "# test_pdf_path = \"data/raw_pdfs/2023_removed.pdf\"\n",
    "# model = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "\n",
    "# config_manager = ConfigurationManager(CONFIG_FILE_PATH, PARAMS_FILE_PATH)\n",
    "# data_ingestion_config = config_manager.get_data_ingestion_params()\n",
    "# image_summarizer_config = config_manager.get_image_summarizer_params()\n",
    "# text_summarizer_config = config_manager.get_text_summarizer_params()\n",
    "\n",
    "# data_ingestion = DataIngestion(data_ingestion_config)\n",
    "# image_summarizer = ImageSummarizer(image_summarizer_config, model)\n",
    "\n",
    "# raw_pdf_elements, report_dir = data_ingestion.process_pdf(test_pdf_path,\n",
    "#                                                           save=True,\n",
    "#                                     strategy=\"hi_res\", # \n",
    "#                                     split_pdf_page=True,  # to process each page seprately\n",
    "#                                     split_pdf_allow_failed=True, # continue processing even if some pages fail\n",
    "#                                     extract_images_in_pdf=True,\n",
    "#                                     infer_table_structure=True,\n",
    "#                                     chunking_strategy=\"by_title\",\n",
    "#                                     extract_image_block_types = [\"Image\" , \"Table\"],\n",
    "#                                     max_characters=4000,\n",
    "#                                     new_after_n_chars=3800,\n",
    "#                                     combine_text_under_n_chars=2000)\n",
    "image_path = \"data/reports/2023_removed/images\"    \n",
    "images_path = image_summarizer.get_image_path(image_path)\n",
    "print(image_path)\n",
    "encoded_images = []\n",
    "image_summaries = []\n",
    "\n",
    "for image in images_path:\n",
    "    encoded_image = image_summarizer.encode_image(image)\n",
    "    image_summaries.append(image_summarizer.image_summarize(encoded_image))\n",
    "    \n",
    "    encoded_images.append(encoded_image)\n",
    "encoded_images, image_summaries = image_summarizer.add_metadata(encoded_images, image_summaries, automatic_metadata=True)\n",
    "\n",
    "# text summaries\n",
    "text_summarizer = TextSummarizer(text_summarizer_config, model)\n",
    "text_data = text_summarizer.get_text_data(raw_pdf_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_summaries = image_summarizer.add_metadata(encoded_images, image_summaries, automatic_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vector store testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:06:23,954 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-02-10 17:06:24,075 - chromadb.config - DEBUG - Starting component System\n",
      "2025-02-10 17:06:24,076 - chromadb.config - DEBUG - Starting component Posthog\n",
      "2025-02-10 17:06:24,076 - chromadb.config - DEBUG - Starting component OpenTelemetryClient\n",
      "2025-02-10 17:06:24,077 - chromadb.config - DEBUG - Starting component SqliteDB\n",
      "2025-02-10 17:06:24,083 - chromadb.config - DEBUG - Starting component SimpleQuotaEnforcer\n",
      "2025-02-10 17:06:24,083 - chromadb.config - DEBUG - Starting component SimpleRateLimitEnforcer\n",
      "2025-02-10 17:06:24,084 - chromadb.config - DEBUG - Starting component LocalSegmentManager\n",
      "2025-02-10 17:06:24,084 - chromadb.config - DEBUG - Starting component LocalExecutor\n",
      "2025-02-10 17:06:24,084 - chromadb.config - DEBUG - Starting component SegmentAPI\n",
      "2025-02-10 17:06:24,091 - chromadb.api.segment - DEBUG - Collection test3 already exists, returning existing collection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x3359fe310> docstore=<langchain_core.stores.InMemoryStore object at 0x32aaf5a90> search_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "from backend.src.storage.chroma_storage import VectorDatabase\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "vector_database_config = config_manager.get_vectordatabase_config()\n",
    "vector_database = VectorDatabase(vector_database_config)\n",
    "vectorstore = vector_database.init_chromadb(embeddings=OpenAIEmbeddings())\n",
    "retriever = vector_database.get_retriever(vectorstore)\n",
    "print(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text, text_summaries, summary_metadata = text_summarizer.generate_summary(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summaries = text_summarizer.add_metadata(raw_text, text_summaries, summary_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_database.store_to_vb(text_summaries, retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:06:31,493 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x1759da430>, 'json_data': {'input': [[791, 2217, 5039, 264, 49304, 1534, 2579, 6211, 71707, 264, 34227, 9451, 477, 264, 50264, 11, 8278, 1376, 13, 1102, 1587, 539, 6782, 904, 40099, 11, 5219, 11, 477, 11944, 828, 13, 578, 6211, 374, 7353, 389, 832, 3185, 323, 259, 9724, 311, 264, 1486, 389, 279, 1023, 11, 6968, 264, 8915, 11, 36612, 11341, 13], [791, 2217, 374, 264, 1584, 4876, 60794, 279, 3430, 315, 4410, 8421, 61748, 320, 18961, 40, 8, 35750, 5707, 505, 220, 679, 24, 311, 220, 2366, 18, 11, 449, 264, 22343, 7953, 220, 2366, 19, 13, 578, 12414, 8183, 11105, 279, 3430, 304, 11441, 824, 20929, 11, 24950, 505, 220, 15, 311, 220, 4364, 13, 578, 16600, 8183, 5039, 279, 25845, 505, 220, 679, 24, 311, 220, 2366, 19, 10, 382, 1622, 3585, 304, 279, 4876, 1473, 12, 763, 220, 679, 24, 11, 279, 3430, 39388, 52085, 2212, 400, 1399, 311, 400, 2031, 824, 20929, 627, 12, 763, 4216, 220, 2366, 15, 11, 1070, 374, 264, 17676, 6068, 11, 449, 7729, 71278, 287, 3770, 400, 508, 824, 20929, 627, 12, 23548, 279, 6068, 11, 279, 3430, 27115, 1421, 9146, 11, 19261, 2212, 400, 1399, 555, 4216, 220, 2366, 16, 627, 12, 5659, 220, 2366, 16, 311, 220, 2366, 17, 11, 279, 3430, 38268, 12207, 11, 1069, 1802, 3485, 400, 4364, 824, 20929, 627, 12, 4740, 279, 16557, 11, 279, 3430, 58054, 719, 8625, 17509, 11, 27276, 4954, 2212, 400, 1490, 555, 220, 2366, 18, 627, 12, 578, 4876, 5764, 264, 59201, 1584, 82382, 264, 5209, 78790, 9293, 3430, 315, 400, 1399, 824, 20929, 369, 468, 27712, 7953, 220, 2366, 19, 13], [791, 2217, 5039, 264, 2579, 11, 8278, 6211, 430, 53291, 264, 34227, 9451, 477, 264, 49304, 1534, 20611, 13, 1102, 706, 264, 7353, 11, 50264, 2385, 389, 279, 2163, 430, 259, 9724, 311, 264, 15376, 1486, 389, 279, 1314, 13, 578, 6211, 374, 11113, 323, 8915, 11, 23377, 11633, 477, 6530, 13, 2684, 527, 912, 40099, 11, 5219, 11, 477, 5217, 3649, 3118, 304, 279, 2217, 13]], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "2025-02-10 17:06:31,498 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "2025-02-10 17:06:31,499 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-02-10 17:06:31,584 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x3364aa640>\n",
      "2025-02-10 17:06:31,586 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x3359c58c0> server_hostname='api.openai.com' timeout=None\n",
      "2025-02-10 17:06:31,607 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x175992fd0>\n",
      "2025-02-10 17:06:31,608 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-10 17:06:31,610 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-10 17:06:31,611 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-10 17:06:31,612 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-10 17:06:31,613 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-10 17:06:32,382 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 10 Feb 2025 11:36:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002-v2'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'193'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5448fdfb9b-cvk6z'), (b'x-envoy-upstream-service-time', b'107'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999665'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'20ms'), (b'x-request-id', b'req_13ca6ba44423796893cd754540b4135c'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zqV55.rl6n9fACLvfFBQfdipqeodRLb5M8f5Nb0j7t4-1739187392-1.0.1.1-OjrAp3C4egEbQYJvH7.u4QMejyvMq6nlo87JFl1OqFWAte6eeb5TUBAua3VzqjU1F0Yvqg_ap2dUd7iuq_qsBQ; path=/; expires=Mon, 10-Feb-25 12:06:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Kft64YvoSQllq6lwCnQ_U10B5no.SPUH37Ex9XBWhhY-1739187392968-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90fbcd5188e79194-DEL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-10 17:06:32,385 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-10 17:06:32,385 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-10 17:06:32,691 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-10 17:06:32,692 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-10 17:06:32,693 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-10 17:06:32,694 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Mon, 10 Feb 2025 11:36:32 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-ada-002-v2'), ('openai-organization', 'user-gccgvei9eaw4a1hksddpirf5'), ('openai-processing-ms', '193'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-5448fdfb9b-cvk6z'), ('x-envoy-upstream-service-time', '107'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999665'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '20ms'), ('x-request-id', 'req_13ca6ba44423796893cd754540b4135c'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=zqV55.rl6n9fACLvfFBQfdipqeodRLb5M8f5Nb0j7t4-1739187392-1.0.1.1-OjrAp3C4egEbQYJvH7.u4QMejyvMq6nlo87JFl1OqFWAte6eeb5TUBAua3VzqjU1F0Yvqg_ap2dUd7iuq_qsBQ; path=/; expires=Mon, 10-Feb-25 12:06:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Kft64YvoSQllq6lwCnQ_U10B5no.SPUH37Ex9XBWhhY-1739187392968-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90fbcd5188e79194-DEL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-02-10 17:06:32,695 - openai._base_client - DEBUG - request_id: req_13ca6ba44423796893cd754540b4135c\n",
      "2025-02-10 17:06:32,719 - chromadb.config - DEBUG - Starting component PersistentLocalHnswSegment\n"
     ]
    }
   ],
   "source": [
    "vector_database.store_to_vb(image_summaries, retriever)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bounce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
