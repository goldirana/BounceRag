{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "import json\n",
    "# import tesseract\n",
    "import pytesseract\n",
    "from typing import *\n",
    "from box import ConfigBox\n",
    "from pathlib import Path\n",
    "import re, sys, os\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "import io\n",
    "import os\n",
    "import base64\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "\n",
    "import uuid\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.utils.common import *\n",
    "from backend.logger import logger\n",
    "from backend.src.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Rajesh goldy\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.21\n",
      "IPython version      : 8.18.1\n",
      "\n",
      "langchain   : 0.3.17\n",
      "unstructured: 0.16.11\n",
      "openai      : 1.61.1\n",
      "pydantic    : 2.10.6\n",
      "pytesseract : 0.3.13\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.1.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a \"Rajesh goldy\" -vmp langchain,unstructured,openai,pydantic,pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.documents.elements import CompositeElement, Table, Image, ListItem  # Import ListItem\n",
    "\n",
    "class Extractor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_metadata(raw_pdf_element: List) -> List:\n",
    "        \"\"\"To get the metadata of elements\n",
    "\n",
    "        Args:\n",
    "            raw_pdf_element (List): list of elements in pdf\n",
    "\n",
    "        Returns:\n",
    "            List: containing meta data\n",
    "        \"\"\"\n",
    "        metadata = []\n",
    "        for element in raw_pdf_element:\n",
    "            metadata.append(element.metadata.to_dict())\n",
    "        \n",
    "        return metadata\n",
    "    \n",
    "    def add_metadata(self, element, **kwargs):\n",
    "        metadata = kwargs\n",
    "        return Document(element, metadata)\n",
    " \n",
    "    def get_year(self, file: str) -> str:\n",
    "        \"\"\"To get the year from file name\n",
    "        Args:\n",
    "            file: name of with extension\"\"\"\n",
    "        \n",
    "        year = re.search(r\"\\d{4}\", file).group()    \n",
    "        if year:\n",
    "            return str(year)\n",
    "        else:\n",
    "            try:\n",
    "                file_name = os.path.split(file)[-1].split(\".\")[0]\n",
    "                return file_name\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in getting year from file: {file} with error: {e}\")\n",
    "                return \"1.0\"\n",
    "        \n",
    "    def extract_data(self, pdf_file, **kwargs):\n",
    "        raw_pdf_elements = partition_pdf(filename=pdf_file, **kwargs)\n",
    "        return raw_pdf_elements\n",
    "    \n",
    "    def generate_unique_id(self, data: Iterator)-> List[str]:\n",
    "        \"\"\"To generate unique id for each element\"\"\"\n",
    "        \n",
    "        unique_id = []\n",
    "        for _ in data:\n",
    "            unique_id.append(str(uuid.uuid4()))\n",
    "        \n",
    "        return unique_id\n",
    "    \n",
    "    def generate_document(self, content: List, id_key: str):\n",
    "        \"\"\"To generate document from content\"\"\"\n",
    "                \n",
    "        ids = self.generate_unique_id(content)\n",
    "        summaries = [Document(page_content=summary, metadata={id_key: ids[index]})\n",
    "                         for index, summary in enumerate(content)]\n",
    "        \n",
    "        return summaries\n",
    "    \n",
    "    @staticmethod\n",
    "    def seprate_data_metadata_for_text(data: List[CompositeElement]) -> Tuple[List, List]:\n",
    "        \"\"\"To seprate data and metadata from dict\n",
    "\n",
    "        Args:\n",
    "            data (List[dict]): List containing raw_pdf_elements\n",
    "            text_name (str): key to get text from dict. Defaults to \"text\"\n",
    "            metadata_name (str): key to get metadata from dict. Defaults to \"metadata\"\n",
    "\n",
    "        Returns:\n",
    "            Tuple: containing text, metadata\n",
    "        \"\"\"\n",
    "        text, metadata = [], []\n",
    "        for i in data:\n",
    "            text.append(str(i))\n",
    "            metadata.append(i.metadata.to_dict())\n",
    "        return text, metadata\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from unstructured.documents.elements import CompositeElement, Table, Image, ListItem  # Import ListItem\n",
    "from unstructured.documents.elements import CompositeElement, Table, Image, ListItem  # Import ListItem\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    raw: str # raw pdf path\n",
    "    reports: str # processed reports path\n",
    "    metadata: list # metadata to collect from raw_pdf_elements\n",
    "    \n",
    "    \n",
    "class ConfigurationManager:\n",
    "    def __init__(self, CONFIG_FILE_PATH, PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(CONFIG_FILE_PATH)\n",
    "        self.params = read_yaml(PARAMS_FILE_PATH)\n",
    "        \n",
    "    def get_data_ingestion_params(self) -> DataIngestionConfig:\n",
    "        params = DataIngestionConfig(\n",
    "            raw=self.config.data_dir.raw,\n",
    "            reports=self.config.data_dir.reports,\n",
    "            metadata=self.config.metadata)\n",
    "        return params\n",
    "    \n",
    "    \n",
    "class DataIngestion(Extractor):\n",
    "    def __init__(self, config):\n",
    "        super(DataIngestion, self).__init__()\n",
    "        self.config = config\n",
    "        self.raw_pdf_elements = None\n",
    "        self.current_pdf_file = None # to keep track of current pdf file being processed (future case)\n",
    "    \n",
    "    \n",
    "    def process_pdf(self, pdf_file_path: str, **kwargs):  \n",
    "        \"\"\"To extract the data from pdf file using unstructured library\n",
    "            Args:\n",
    "                pdf_file_path (str): full path of pdf file\n",
    "\n",
    "            Returns:\n",
    "                configBox: Box containing text_elements, table_elements, list_items\n",
    "        \"\"\"\n",
    "        \n",
    "        file_name = os.path.split(pdf_file_path)[-1].split(\".\")[0] # get the filename from file name and set it as directory name\n",
    "        report_dir = os.path.join(self.config.reports, file_name) \n",
    "        create_directory(report_dir, is_extension_present=False) # create directory with file_name\n",
    "        if kwargs.get(\"extract_image_block_output_dir\", None) == None: # to create image folder in report_dir\n",
    "            kwargs[\"extract_image_block_output_dir\"] = os.path.join(report_dir, \"images\")\n",
    "            \n",
    "        raw_pdf_elements = self.extract_data(pdf_file_path, **kwargs)\n",
    "        \n",
    "        return raw_pdf_elements, report_dir\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 19:55:35,222 - root - INFO - Yaml read successfully from config.yaml\n",
      "2025-02-09 19:55:35,229 - root - ERROR - FileNotFoundError: params.yaml\n"
     ]
    }
   ],
   "source": [
    "config_manager = ConfigurationManager(CONFIG_FILE_PATH, PARAMS_FILE_PATH)\n",
    "data_extractor_config = config_manager.get_data_ingestion_params()\n",
    "\n",
    "data_extractor = DataIngestion(data_extractor_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_pdf_dir = \"backend/data/reports/2023_removed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, current_pdf_dir = data_extractor.process_pdf(pdf_file_path=\"backend/data/raw_pdfs/2023_removed.pdf\",\n",
    "                                  save=True,\n",
    "                                    strategy=\"hi_res\", # \n",
    "                                    split_pdf_page=True,  # to process each page seprately\n",
    "                                    split_pdf_allow_failed=True, # continue processing even if some pages fail\n",
    "                                    extract_images_in_pdf=True,\n",
    "                                    infer_table_structure=True,\n",
    "                                    chunking_strategy=\"by_title\",\n",
    "                                    extract_image_block_types = [\"Image\" , \"Table\"],\n",
    "                                    max_characters=4000,\n",
    "                                    new_after_n_chars=3800,\n",
    "                                    combine_text_under_n_chars=2000\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = data_extractor.get_text_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass \n",
    "class TextSummarizerConfig:\n",
    "    model: str # model name used to generate summary\n",
    "    text_summary_dir: str # path to save text summaries\n",
    "    summarizer_prompt_dir: str\n",
    "    text_summarizer_prompt: str \n",
    "    \n",
    "class ConfigurationManager:\n",
    "    def __init__(self, CONFIG_FILE_PATH, PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(CONFIG_FILE_PATH)\n",
    "        self.params = read_yaml(PARAMS_FILE_PATH)\n",
    "        \n",
    "    def get_text_summarizer(self) -> TextSummarizerConfig:\n",
    "        summarizer_prompt_dir=read_json(self.config.prompts.summarizer_prompt_dir)\n",
    "        \n",
    "        params = TextSummarizerConfig(\n",
    "            model=self.config.text_summarizer.model,\n",
    "            text_summary_dir=self.config.text_summarizer.text_summary_dir,\n",
    "            summarizer_prompt_dir=self.config.prompts.summarizer_prompt_dir,\n",
    "            text_summarizer_prompt=summarizer_prompt_dir[\"text_summarizer_prompt\"],\n",
    "        )\n",
    "        return params\n",
    "    \n",
    "class TextSummarizer(Extractor):\n",
    "    def __init__(self, config, model):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        \n",
    "    def generate_summary(self, docs: List[dict]):\n",
    "        \"\"\"To generate summary of the text\n",
    "\n",
    "        Args:\n",
    "            model (object): model used to generate summary of text\n",
    "            docs (List[dict]): List containing dict >> text with metadata\n",
    "                len of docs = len of dict containing text with metadata\n",
    "                        dict -> text, metadata \n",
    "        \"\"\"\n",
    "                    \n",
    "        raw_text, metadata = Extractor.seprate_data_metadata_for_text(docs)\n",
    "        prompt = ChatPromptTemplate.from_template(self.config.text_summarizer_prompt)\n",
    "        summarize_chain = {\"element\": lambda x: x} | prompt | self.model | StrOutputParser()\n",
    "        summaries = summarize_chain.batch(raw_text, {\"max_concurrency\": 5})\n",
    "        return raw_text, summaries, metadata\n",
    "    \n",
    "    def get_text_data(self, raw_pdf_elements)-> List[Any]:\n",
    "        text = []\n",
    "        for element in raw_pdf_elements:\n",
    "            if isinstance(element, CompositeElement) or isinstance(element, ListItem):\n",
    "                text.append(element)\n",
    "        return text\n",
    "    \n",
    "    def add_metadata(self,raw_text, summaries, summary_metadata: dict=None):\n",
    "        uuids = [str(uuid.uuid4()) for i in raw_text]\n",
    "        \n",
    "        raw_text_with_metadata = list(zip(raw_text, uuids))\n",
    "        \n",
    "        summaries_with_metadata = []\n",
    "        for index, data in enumerate(zip(summaries, summary_metadata)):\n",
    "            summary, metadata = data\n",
    "            metadata[\"doc_id\"] = uuids[index]\n",
    "            summaries_with_metadata.append(Document(page_content=summary, metadata=metadata))\n",
    "        \n",
    "        return raw_text_with_metadata, summaries_with_metadata\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 20:15:07,941 - root - INFO - Yaml read successfully from config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 20:15:07,971 - root - ERROR - FileNotFoundError: params.yaml\n",
      "2025-02-09 20:15:07,982 - root - INFO - Json object read sucessfully \n"
     ]
    }
   ],
   "source": [
    "config_manager = ConfigurationManager(CONFIG_FILE_PATH, PARAMS_FILE_PATH)\n",
    "text_summarizer_config = config_manager.get_text_summarizer()\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "text_summarizer = TextSummarizer(text_summarizer_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 20:15:46,038 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.smith.langchain.com:443\n",
      "2025-02-09 20:15:46,648 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Act as an assistant tasked with summarizing the tables and text. Give a concise summary of the table or text. Table or text chunk: Use of Non-GAAP Financial Information — This presentation includes non-GAAP financial measures, which help facilitate comparison of company operating performance across periods and with peer companies. Any historical non-GAAP measures included herein will be accompanied by a reconciliation to the nearest corresponding GAAP measure both at the end of this presentation and on our website at www.conocophillips.com/nongaap. For forward-looking non-GAAP measures, we are unable to provide a reconciliation to the most comparable GAAP financial measures because the information needed to reconcile these measures is dependent on future events, many of which are outside management\\'s control as described above. Additionally, estimating such GAAP measures and providing a meaningful reconciliation consistent with our accounting policies for future periods is extremely difficult and requires a level of precision that is unavailable for these future periods and cannot be accomplished without unreasonable effort. Forward looking non-GAAP measures are estimated consistent with the relevant definitions and assumptions.\\n\\nCautionary Note to U.S. Investors - The SEC permits oil and gas companies, in their filings with the SEC, to disclose only proved, probable and possible reserves. We use terms and metrics such as \"resource\" or “Estimated Ultimate Recovery (EUR)” in this presentation that we are prohibited from using in filings with the SEC under the SEC’s guidelines. U.S. investors are urged to consider closely the oil and gas disclosures in our Form 10-K and other reports and filings with the SEC. Copies are available from the SEC and from the ConocoPhillips website.\\n\\nincluded\\n\\nConocoPhillips 3\\n\\nConocoPhillios Remains the Must-Own E&P Company\\n\\nThe Macro\\n\\nWhat You\\'ll Hear Today\\n\\nOil Price ($/BBL WTI)\\n\\n120 100 80 60 sland A —_ss—s— FRR —CiCi(C(C(C(C(C#CA HHS ttt teeter eeeeeerecceeeees > $60/BBL WT Mid-Cycle 40 Planning Price 20 2019 2021 2023 2024+\\n\\nWe are committed to delivering superior returns on and of capital through the cycles\\n\\nWe have a deep, durable and diverse portfolio\\n\\nWe are progressing our'}], 'model': 'gpt-4o', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2025-02-09 20:15:46,649 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Act as an assistant tasked with summarizing the tables and text. Give a concise summary of the table or text. Table or text chunk: Where, in any forward-looking statement, the company expresses an expectation or belief as to future results, such expectation or belief is based on management's good faith plans and objectives under the assumptions set forth above (unless noted otherwise) and believed to be reasonable as of April 12, 2023, the date of this presentation. These statements are not guarantees of future performance and involve certain risks and uncertainties and are subject to change as management is continually assessing factors beyond our control that may or may not be currently known. Given the foregoing and the extended time horizon of this presentation, actual outcomes and results will likely differ from what is expressed or forecast in the forward-looking statements, and such differences may be material Factors that could cause actual results or events to differ materially from what is presented include changes in commodity prices, including a prolonged decline in these prices relative to historical or future expected levels; global and regional changes in the demand, supply, prices, differentials or other market conditions affecting oil and gas, including changes resulting from any ongoing military conflict, including the conflict between Russia and Ukraine and the global response to such conflict, security threats on facilities and infrastructure, or from a public health crisis or from the imposition or lifting of crude oil production quotas or other actions that might be imposed by OPEC and other producing countries and the resulting company or third-party actions in response to such changes; insufficient liquidity or other factors, such as those listed herein, that could impact our ability to repurchase shares and declare and pay dividends such that we suspend our share repurchase program and reduce, suspend, or totally eliminate dividend payments in the future, whether variable or fixed; changes in expected levels of oil and gas reserves or production; potential failures or delays in achieving expected reserve or production levels from existing and future oil and gas developments, including due to operating hazards, drilling risks or unsuccessful exploratory activities; unexpected cost increases, inflationary pressures or technical difficulties in constructing, maintaining or modifying company facilities; legislative and regulatory initiatives addressing global climate change or other environmental concerns; public health crises, including pandemics (such as COVID-19) and epidemics and any impacts or related company or government policies or actions; investment in and development of competing or alternative energy sources; potential failures or delays in delivering on our current or future low-carbon strategy, including our inability to develop new technologies; disruptions or interruptions impacting the transportation for our oil and gas production; international monetary conditions and exchange rate fluctuations; changes in international trade relationships or governmental policies, including the imposition of price caps or the imposition of trade restrictions or tariffs on any materials or products (such as aluminum and steel) used in the operation of our business, including any sanctions imposed as a result of any ongoing military conflict, including the conflict between Russia and Ukraine; our ability to collect payments when due, including our ability to collect payments from the government of Venezuela or PDVSA; our ability to complete any announced or any future dispositions or acquisitions on time, if at all; the possibility that regulatory approvals for any announced or any future dispositions or acquisitions will not be received on a timely basis, if at all, or that such approvals may require modification to the terms of the transactions or our remaining business; business disruptions following any announced or future dispositions or acquisitions, including the diversion of management time and attention; the ability to deploy\"}], 'model': 'gpt-4o', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2025-02-09 20:15:46,650 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Act as an assistant tasked with summarizing the tables and text. Give a concise summary of the table or text. Table or text chunk: 2050 Net-Zero ambition and\\n\\naccelerating our 2030 GHG emissions intensity reduction target\\n\\nConocoPhillips 5\\n\\nWe Are Committed to Our Returns-Focused Value Proposition\\n\\nTriple Mandate Aligned to Business Realities\\n\\nMEET DELIVER TRANSITION COMPETITIVE PATHWAY DEMAND RETURNS ACHIEVE NET-ZERO EMISSIONS AMBITION!\\n\\nFoundational Principles Balance Sheet Strength AN ww \"ned RETURNS On Discipline Peer-Leading Investments Distributions ESG Excellence 009 On Deliver Superior Returns Through Cycles\\n\\nScope 1 and 2 emissions on a gross operated and net equity basis. Cash from operations (CFO) is a non-GAAP measure defined in the Appendix.\\n\\nWw\\n\\nClear and Consistent Priorities\\n\\n1\\n\\nSustain production and pay dividend\\n\\n2 Annual dividend growth\\n\\n3 A-rated balance sheet\\n\\nA\\n\\n>30% of CFO shareholder payout\\n\\n5\\n\\nDisciplined investment to enhance returns\\n\\nConocoPhillips 6\\n\\nWe Are Continuously Improving\\n\\n2016 2019 2022 Foundational $43/BBL WTI $57/BBL WTI $94/BBL WTI Principles Return on Capital Employed “4% 10% 27% JADA] Peer-Leading Ox Distributions Return of Capital! $1.11/share $4.45/share $11.73/share and Returns — Balance Sheet Net Debt $24B $7B $7B S= | Strength Cash From Operations | Ereei@ech low $5B | $0B $12B | $5B $29B | $18B Resource . 7 . iM Disciplined <$40/BBL WTI 10 BBOE 15 BBOE 20 BBOE Investments Production 1.6 MMBOED 1.3 MMBOED 1.7 MMBOED Emissions Intensity? ~39 ~36 ~22 ESG (kg CO,e/BOE) wo) Excellence\\n\\n\\'Defined in the Appendix and presented on a per-share basis using average outstanding diluted shares. *Gross operated GHG emissions (Scope 1 and 2), 2022 is a preliminary estimate. Cash from operations (CFO), free cash flow (FCF), net debt and return on capital employed (ROCE) are non-GAAP measures. Definitions and reconciliations are included in the Appendix.\\n\\nConocoPhillips 7\\n\\nWe Have a Compelling 10-Year Plan that Sets us Apart\\n\\nWw\\n\\n10-Year Plan ($B)\\n\\n2023-2032\\n\\nPeer leading ROCE improving through time\\n\\n$350\\n\\n$300 BL WTI $250 Upside Sensitivity $80/B ae $200 Distributions 30% of CFO $150 CFO at Distribution $60/BBL WTI Commitment Mid-Cycle $100 Planning Price Capital $50 se Sources Uses\\n\\nTop quartile ordinary dividend growth\\n\\n>90% market cap? distributed\\n\\n~$35/BBL WTI FCF Breakeven?'}], 'model': 'gpt-4o', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2025-02-09 20:15:46,653 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Act as an assistant tasked with summarizing the tables and text. Give a concise summary of the table or text. Table or text chunk: Cautionary Statement\\n\\nThis presentation provides management\\'s current operational plan for ConocoPhillips over roughly the next decade, for the assets currently in our portfolio, and is subject to multiple assumptions, including, unless otherwise specifically noted: * anoil price of $60/BBL West Texas Intermediate in 2022 dollars, escalating at 2.25% annually;\\n\\n* anoil price of $65/BBL Brent in 2022 dollars, escalating at 2.25% annually;\\n\\n* agas price of $3.75/MMBTU Henry Hub in 2022 dollars, escalating at 2.25%\\n\\nannually;\\n\\nan international gas price of $8/MMBTU Title Transfer Facility & Japan Korea Marker in 2022 dollars, escalating at 2.25% annually;\\n\\n* cost and capital escalation in line with price escalation; planning case at $60/BBL WTI assumes capital de-escalation from levels\\n\\nobserved in 2022;\\n\\n* all production compound annual growth rates (CAGR) are calculated for the 10-year period 2023 — 2032;\\n\\ninclusion of carbon tax in the cash flow forecasts for assets where a tax is currently assessed. If no carbon tax exists for the asset, it is not included in the cash flow forecasts;\\n\\nCost of Supply displayed in WTI, includes carbon tax where carbon policy exists and a proxy carbon price for assets without existing carbon policies. Please refer to the Cost of Supply definition in the Appendix for additional information on how carbon costs are in the Cost of Supply calculation.\\n\\nAs a result, this presentation contains forward-looking statements as defined under the federal securities laws. Forward-looking statements relate to future events, plans and anticipated results of operations, business strategies, and other aspects of our operations or operating results. Graphics that project into a future date constitute forward-looking statements. Also, words and phrases such as “anticipate,” \"estimate,\" \"believe,\" \"budget,\" \"continue,\" \"could,\" \"intend,\" \"may,\" \"plan,\" “potential,” \"predict,\" \"seek,\" \"should,\" \"will,\" \"would,\" \"expect,\" \"objective,\" \"projection,\" \"forecast,\" \"goal,\" \"guidance,\" \"outlook,\" \"effort,\" \"target\" and other similar words can be used to identify forward-looking statements. However, the absence of these words does not mean that the statements are not forward-looking.'}], 'model': 'gpt-4o', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2025-02-09 20:15:46,656 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Act as an assistant tasked with summarizing the tables and text. Give a concise summary of the table or text. Table or text chunk: net proceeds from our announced or any future dispositions in the manner and timeframe we anticipate, if at all; potential liability for remedial actions under existing or future environmental regulations; potential liability resulting from pending or future litigation, including litigation related directly or indirectly to our transaction with Concho Resources Inc.; the impact of competition and consolidation in the oil and gas industry; limited access to capital or insurance or significantly higher cost of capital or insurance related to illiquidity or uncertainty in the domestic or international financial markets or investor sentiment; general domestic and international economic and political conditions or developments, including as a result of any ongoing military conflict, including the conflict between Russia and Ukraine; changes in fiscal regime or tax, environmental and other laws applicable to our business; and disruptions resulting from accidents, extraordinary weather events, civil unrest, political events, war, terrorism, cybersecurity threats or information technology failures, constraints or disruptions; and other economic, business, competitive and/or regulatory factors affecting our business generally as set forth in our filings with the Securities and Exchange Commission. Unless legally required, ConocoPhillips expressly disclaims any obligation to update any forward-looking statements, whether as a result of new information, future events or otherwise. We assume no duty to update these statements as of any future date and neither future distribution of this material nor the continued availability of this material in archive form on our website should be deemed to constitute an update or re-affirmation of these figures as of any future date. Any future update of these figures will be provided only through a public disclosure indicating that fact.'}], 'model': 'gpt-4o', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2025-02-09 20:15:46,658 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-02-09 20:15:46,659 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-02-09 20:15:46,660 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-02-09 20:15:46,661 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-02-09 20:15:46,662 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-02-09 20:15:46,665 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-02-09 20:15:46,665 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-02-09 20:15:46,666 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-02-09 20:15:46,666 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-02-09 20:15:46,666 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-02-09 20:15:46,676 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 \"GET /info HTTP/1.1\" 200 672\n",
      "2025-02-09 20:15:49,499 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32a214c10>\n",
      "2025-02-09 20:15:49,499 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32a212e20>\n",
      "2025-02-09 20:15:49,499 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32a217d00>\n",
      "2025-02-09 20:15:49,548 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32a214760>\n",
      "2025-02-09 20:15:49,550 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x32c8facc0> server_hostname='api.openai.com' timeout=None\n",
      "2025-02-09 20:15:49,551 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x32c8facc0> server_hostname='api.openai.com' timeout=None\n",
      "2025-02-09 20:15:49,553 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x32c8facc0> server_hostname='api.openai.com' timeout=None\n",
      "2025-02-09 20:15:49,554 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x32c8facc0> server_hostname='api.openai.com' timeout=None\n",
      "2025-02-09 20:15:49,592 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32cc490d0>\n",
      "2025-02-09 20:15:49,592 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32a212df0>\n",
      "2025-02-09 20:15:49,592 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32a214730>\n",
      "2025-02-09 20:15:49,594 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32a214be0>\n",
      "2025-02-09 20:15:49,596 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,597 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,598 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,600 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,601 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-09 20:15:49,601 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-09 20:15:49,603 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-09 20:15:49,603 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-09 20:15:49,605 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,605 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,606 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,607 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,608 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-09 20:15:49,615 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,611 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-09 20:15:49,612 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-09 20:15:49,618 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,617 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:49,609 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-09 20:15:49,629 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:50,300 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 33\n",
      "2025-02-09 20:15:50,512 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32a2142b0>\n",
      "2025-02-09 20:15:50,513 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x32c8facc0> server_hostname='api.openai.com' timeout=None\n",
      "2025-02-09 20:15:50,533 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32be7d7c0>\n",
      "2025-02-09 20:15:50,534 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:50,535 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-09 20:15:50,536 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:50,536 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-09 20:15:50,536 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:52,588 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Feb 2025 14:45:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'2161'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'497'), (b'x-ratelimit-remaining-tokens', b'28252'), (b'x-ratelimit-reset-requests', b'256ms'), (b'x-ratelimit-reset-tokens', b'3.494s'), (b'x-request-id', b'req_84badcf9b0f2453da7bb3dc62989c8a1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9LxVUKoGXcN0E4GWa.qc0Jh5or5JYyD5coBvxjL3TWE-1739112353-1.0.1.1-xFfZ5J2QvPyiDkRdcBVxod8CRpTcNClSoUvtUj_2MJstvFM.VOKQdz3056GXIz8ViqInXQHHf2mMoL.iIRPICQ; path=/; expires=Sun, 09-Feb-25 15:15:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=GGRHi2yW5duHP8eoo9_L766fYZALEGscRngzgkZtPC0-1739112353138-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f4a53c8a0654e8-DEL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:52,591 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 20:15:52,593 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:52,599 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-09 20:15:52,599 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-09 20:15:52,600 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-09 20:15:52,601 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 09 Feb 2025 14:45:53 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-gccgvei9eaw4a1hksddpirf5'), ('openai-processing-ms', '2161'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '30000'), ('x-ratelimit-remaining-requests', '497'), ('x-ratelimit-remaining-tokens', '28252'), ('x-ratelimit-reset-requests', '256ms'), ('x-ratelimit-reset-tokens', '3.494s'), ('x-request-id', 'req_84badcf9b0f2453da7bb3dc62989c8a1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=9LxVUKoGXcN0E4GWa.qc0Jh5or5JYyD5coBvxjL3TWE-1739112353-1.0.1.1-xFfZ5J2QvPyiDkRdcBVxod8CRpTcNClSoUvtUj_2MJstvFM.VOKQdz3056GXIz8ViqInXQHHf2mMoL.iIRPICQ; path=/; expires=Sun, 09-Feb-25 15:15:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=GGRHi2yW5duHP8eoo9_L766fYZALEGscRngzgkZtPC0-1739112353138-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90f4a53c8a0654e8-DEL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:52,602 - openai._base_client - DEBUG - request_id: req_84badcf9b0f2453da7bb3dc62989c8a1\n",
      "2025-02-09 20:15:52,646 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Act as an assistant tasked with summarizing the tables and text. Give a concise summary of the table or text. Table or text chunk: ~6% CFO CAGR, ~11% FCF CAGR\\n\\nUnhedged for price upside\\n\\n‘Cash includes cash, cash equivalents, restricted cash and short-term investments. *Market cap of ~$121B at March 31, 2023, close. *Average over the next 10 years. CAGRs calculated from FY2024 at $60/BBL WTI. Cash from operations (CFO), free cash flow (FCF) and return on capital employed (ROCE) are non-GAAP measures.\\n\\nDefinitions are included in the Appendix.\\n\\nConocoPhillips 8\\n\\nStrategy Powers Our Returns-Focused Value Proposition\\n\\nTE\\n\\né) Y\\n\\nRigorous Capital Allocation Framework\\n\\nDifferentiated Portfolio Depth, Durability and Diversity\\n\\nCommitment to disciplined reinvestment rate\\n\\n~20 BBOE, <$40/BBL WTI low Cost of Supply resource base\\n\\nCost of Supply analysis informs investment decisions\\n\\nLeading Lower 48 unconventional position, complemented with premium Alaska and International assets\\n\\nBalance of short-cycle, flexible unconventional with select longer-cycle, low-decline conventional\\n\\nStrong track record of active portfolio management\\n\\nReinvestment rate is a non-GAAP measure defined in the Appendix.\\n\\nWw\\n\\nry QO, Oo | ar\\n\\nValued Role in the Energy Transition\\n\\nAccelerating GHG-intensity reduction target through 2030\\n\\nBuilt attractive LNG portfolio\\n\\nEvaluating longer term low-carbon options in hydrogen and CCS\\n\\nConocoPhillips 10\\n\\nCommitment to Disciplined Reinvestment Rate\\n\\nWw\\n\\nIndustry Growth Focus\\n\\nConocoPhillips Strategy Reset\\n\\nDisciplined Reinvestment Rate is the Foundation for Superior Returns on and of Capital, while Driving Durable CFO Growth\\n\\n>100% Reinvestment Rate\\n\\n<60% Reinvestment Rate\\n\\n~50% 10-Year Reinvestment Rate\\n\\n~6% CFO CAGR 2024-2032\\n\\nat $60/BBL WTI Mid-Cycle Planning Price\\n\\n= 100% oO 5 fag ¢ oO £ 8 ao f= oO a E = Cc xt\\n\\n75%\\n\\n50%\\n\\no D oO g xt a = a . 5 UO\\n\\n25%\\n\\n~$75/BBL WTI Average\\n\\n~$63/BBL WTI Average\\n\\nat $80/BBL WTI\\n\\n_, at $80/BBL wTl _, at $80/BBL WTI at $60/BBL at $60/BBL WTI WTI\\n\\n0%\\n\\n2012-2016\\n\\n2017-2022\\n\\n2023E\\n\\n2024-2028\\n\\n2029-2032\\n\\n® Historic Reinvestment Rate\\n\\n@ Reinvestment Rate at $60/BBL WTI'}], 'model': 'gpt-4o', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2025-02-09 20:15:52,649 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-02-09 20:15:52,651 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:52,651 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-09 20:15:52,652 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:52,655 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-09 20:15:52,655 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:53,318 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Feb 2025 14:45:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'2835'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'497'), (b'x-ratelimit-remaining-tokens', b'27750'), (b'x-ratelimit-reset-requests', b'332ms'), (b'x-ratelimit-reset-tokens', b'4.498s'), (b'x-request-id', b'req_716a21c1d240b9d27838c97e2c984109'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=e2iU4pN3k9iifyC36hHLv2mOZ55APOYJpP9K.LGgsvI-1739112353-1.0.1.1-2zfMoHZ4fmyk6_zESkWbj80infx9u7JbvNvR3vQFEMEaK3oz5Pzlj8lqn_Q0bWt_MMIJD8jNmEbb5R7OZsOLJw; path=/; expires=Sun, 09-Feb-25 15:15:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=yKx8tktj8TDQYWd.QH_miJ5jmz59jYVmI2DRo_jt.5o-1739112353869-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f4a53c8b4c59e2-DEL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:53,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 20:15:53,321 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:53,326 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-09 20:15:53,327 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-09 20:15:53,327 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-09 20:15:53,328 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 09 Feb 2025 14:45:53 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-gccgvei9eaw4a1hksddpirf5'), ('openai-processing-ms', '2835'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '30000'), ('x-ratelimit-remaining-requests', '497'), ('x-ratelimit-remaining-tokens', '27750'), ('x-ratelimit-reset-requests', '332ms'), ('x-ratelimit-reset-tokens', '4.498s'), ('x-request-id', 'req_716a21c1d240b9d27838c97e2c984109'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=e2iU4pN3k9iifyC36hHLv2mOZ55APOYJpP9K.LGgsvI-1739112353-1.0.1.1-2zfMoHZ4fmyk6_zESkWbj80infx9u7JbvNvR3vQFEMEaK3oz5Pzlj8lqn_Q0bWt_MMIJD8jNmEbb5R7OZsOLJw; path=/; expires=Sun, 09-Feb-25 15:15:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=yKx8tktj8TDQYWd.QH_miJ5jmz59jYVmI2DRo_jt.5o-1739112353869-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90f4a53c8b4c59e2-DEL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:53,328 - openai._base_client - DEBUG - request_id: req_716a21c1d240b9d27838c97e2c984109\n",
      "2025-02-09 20:15:53,338 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Act as an assistant tasked with summarizing the tables and text. Give a concise summary of the table or text. Table or text chunk: === Reinvestment Rate at $80/BBL WTI\\n\\nReinvestment rate and cash from operations (CFO) are non-GAAP measures. Definitions and reconciliations are included in the Appendix.\\n\\nConocoPhillips 11\\n\\nCost of Supply Analysis Informs Investment Decisions\\n\\nWw\\n\\nCost of Supply = Our North Star\\n\\n$/BBL WTI Oil Price Required to Achieve a Point-Forward 10% Return\\n\\nWTI Cost of Supply ($/BBL)\\n\\nFully Burdened Metric | With All Components Rigorously Calculated For Each Entity Ss -s40/e8 G&A Transport Lifting Capital OPEX Royalty Taxes Product Mix Differential to WTI WTI CoS Facilities Wells\\n\\nLow Cost of Supply Wins\\n\\nReflecti f ical Permi. I it well. eflective of a typical Permian development we\\n\\nConocoPhillips 12\\n\\nSecondary Investment Criteria Reinforce Resilient, Durable Returns\\n\\nww\\n\\nInvestment Criteria\\n\\nBalanced, Diversified, Disciplined Production Growth\\n\\nProduction Mix'\\n\\na = QZ c £ a\\n\\na 2 O > = zg fe) o ,)\\n\\nDisciplined Reinvestment Rate Returns of capital\\n\\nCost of Supply Returns on capital\\n\\nBalance of short-cycle, flexible unconventional with longer-cycle, low-decline conventional\\n\\n. Product mix and market exposure\\n\\n, , Predictable execution\\n\\nOil ~55% NGL ~15% North American Gas ~15% International Gas ~15%\\n\\nProduction (MBOED)\\n\\n2500 ~4-5% PNG = Surmont Production CAGE ~2% CAGR 2,000 Conventional ~3% CAGR 1,500 + 000 ' . Unconventional (Lower 48 + Montney) an ee 500 0\\n\\n2023E\\n\\n2032\\n\\n‘Average anticipated production mix from 2023-2032; oil includes bitumen. Reinvestment rate is a non-GAAP measure defined in the Appendix.\\n\\nConocoPhillips 13\\n\\nOur Differentiated Portfolio: Deep, Durable and Diverse\\n\\n~20 BBOE of Resource\\n\\nDiverse Production Base\\n\\nUnder $40/BBL Cost of Supply\\n\\n10-Year Plan Cumulative Production (BBOE)\\n\\n$50\\n\\n~ $3 2/BBL Average Cost of Supply\\n\\n$46 a $30 $20 $0 0 5 10 15 20 Resource (BBOE) W Lower 48 Canada B Alaska M@ EMENA BB Asia Pacific\\n\\n= a = Qa vi 8 E\\n\\nLower 48 Alaska GKA GWA GPA WNS EMENA Norway Qatar Libya Eagle Ford Other\\n\\nCosts assume a mid-cycle price environment of $60/BBL WTI.\\n\\nWw\\n\\nConocoPhillips 14\\n\\nStrong Track Record of Active Portfolio Management\\n\\nww\"}], 'model': 'gpt-4o', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2025-02-09 20:15:53,340 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-02-09 20:15:53,341 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:53,341 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-09 20:15:53,342 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:53,342 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-09 20:15:53,342 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:53,666 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 33\n",
      "2025-02-09 20:15:53,764 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Feb 2025 14:45:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'2894'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'26900'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'6.198s'), (b'x-request-id', b'req_658fafe58c7c39f426c0a30995e5e234'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TI5Y3UxNrL0pmE48yIGvrVAtlwrdK4LGNAwm5fBySD4-1739112354-1.0.1.1-18wV.vJTSxVH36qGQsmkh6aHub2HhKuURZQpWoSyWbhAF_v3u3ebbPArgvicp1zvQ9ehcQSvkTl1TwWDlQ3gsg; path=/; expires=Sun, 09-Feb-25 15:15:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=uy2TmR3WwC3OR9bVVC1b_K6RMclJSRjC60nGyi7vzLQ-1739112354316-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f4a5425ab459d0-DEL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:53,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 20:15:53,766 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:53,767 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-09 20:15:53,767 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-09 20:15:53,768 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-09 20:15:53,768 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 09 Feb 2025 14:45:54 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-gccgvei9eaw4a1hksddpirf5'), ('openai-processing-ms', '2894'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '30000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '26900'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '6.198s'), ('x-request-id', 'req_658fafe58c7c39f426c0a30995e5e234'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=TI5Y3UxNrL0pmE48yIGvrVAtlwrdK4LGNAwm5fBySD4-1739112354-1.0.1.1-18wV.vJTSxVH36qGQsmkh6aHub2HhKuURZQpWoSyWbhAF_v3u3ebbPArgvicp1zvQ9ehcQSvkTl1TwWDlQ3gsg; path=/; expires=Sun, 09-Feb-25 15:15:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=uy2TmR3WwC3OR9bVVC1b_K6RMclJSRjC60nGyi7vzLQ-1739112354316-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90f4a5425ab459d0-DEL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:53,769 - openai._base_client - DEBUG - request_id: req_658fafe58c7c39f426c0a30995e5e234\n",
      "2025-02-09 20:15:53,776 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Act as an assistant tasked with summarizing the tables and text. Give a concise summary of the table or text. Table or text chunk: 2016\\n\\n2022\\n\\nProduction _ » 1.6 MMBOED WNS and GkA Montney — Concho and » 1.7 MMBOED Working Interest Acreage Shell Permian APLNG Consolidations Acquisition Acquisitions — Acquisition 2018 2020 2022 aoe seaciasly > <$40/BBLWT| 9 ee} ~ $3 2/BBL 2017 2019 2021 Resource Life » >18 years | | » >30 years San Juan Exit U.K. Exit Niobrara and Indonesia Emissions Canada Cenovus Australia-West Exit Intensity) ” ~39 kg CO,e/BOE Transaction Exits » ~22 kg\\n\\nWTI\\n\\nCO,e/BOE\\n\\nCost of Supply Framework Drives Disciplined Transactions\\n\\n~$25B of Both Acquisitions and Divestitures Since 20162\\n\\n'Gross operated GHG emissions (Scope 1 and 2), 2022 is a preliminary estimate. Dispositions include contingent payment proceeds and sale of CVE shares.\\n\\nConocoPhillips 15\\n\\nAccelerating Our GHG-Intensity Reduction Target Through 2030\\n\\nWw\\n\\nEmissions Reduction Opportunities\\n\\nPathway to Net-Zero!\\n\\n50\\n\\nEmissions Intensity (kg CO2e/BOE)\\n\\nMethane Venting and Flaring\\n\\nElectrification\\n\\neg Optimization and Efficiency\\n\\nStrategic Pilots and Studies\\n\\n50% Reduction 60% Reduction {Ep 2016 2022E 2030 2050 @ Gross Operated Net Equity Near-Term (2025) * Zero routine flaring by 20252 * NEW: Reduce GHG intensity 50-60% (from 40-50%)? * Near-zero methane intensity target <1.5 kg CO,e/BOE Medium-Term (2030) Long-Term (2050) * Net-zero emissions ambition’\\n\\n40\\n\\n30\\n\\n50\\n\\n10\\n\\n0\\n\\nProgressing Toward Net-Zero Ambition\\n\\nScope 1 and 2 emissions on a gross operated and net equity basis. In line with the World Bank Zero Routine Flaring initiative, ConocoPhillips premise is five years earlier than World Bank 2030 goal. 3Reduction from a 2016 baseline.\\n\\nConocoPhillips 16\\n\\nLNG: A Crucial Fuel for Energy Transition\\n\\nWw\\n\\nU.S. Electric Power Sector Emissions Drop with Shift from Coal to Natural Gas!\\n\\n95000\\n\\nGlobal Coal Consumption? Has Yet to Definitively Peak\\n\\n: 60% C40 Z > 30% Reduction gn, un In 5 EMISSIONS 2,500 é = 40% Coal ae S e ao — a s Total LL fe) oe vom 17% 8 ae 1,750 3 Gas S = 20% =~ ————————__ 1,000 2001 2021 2001 2021\\n\\n=\\n\\n7,000 5,000\\n\\n3,000\\n\\n2000\\n\\n2010\\n\\n2020\"}], 'model': 'gpt-4o', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2025-02-09 20:15:53,777 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-02-09 20:15:53,777 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:53,778 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-09 20:15:53,778 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:53,779 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-09 20:15:53,779 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:54,207 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Feb 2025 14:45:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'3856'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'29391'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.218s'), (b'x-request-id', b'req_dd561488ae6c0dc0c06546d229e0f51a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pw9VWThCSTALEfYTc.bHlzbRLQjpakEQqBSIGW91Pmg-1739112354-1.0.1.1-KMC7NCtexHTKqbWVOU2FDuu937AnU.JP7b_AbkvR_B_A2bL_XprbUgjq805A_tZoHrVO9St4VytOmMKaVfCdiA; path=/; expires=Sun, 09-Feb-25 15:15:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=cIlDk24NddkO9tY4kicu9vo29YVg4W9bhuwzr6szBjI-1739112354742-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f4a53c892b5514-DEL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:54,208 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 20:15:54,209 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:54,210 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-09 20:15:54,211 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-09 20:15:54,211 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-09 20:15:54,212 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 09 Feb 2025 14:45:54 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-gccgvei9eaw4a1hksddpirf5'), ('openai-processing-ms', '3856'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '30000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '29391'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '1.218s'), ('x-request-id', 'req_dd561488ae6c0dc0c06546d229e0f51a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=pw9VWThCSTALEfYTc.bHlzbRLQjpakEQqBSIGW91Pmg-1739112354-1.0.1.1-KMC7NCtexHTKqbWVOU2FDuu937AnU.JP7b_AbkvR_B_A2bL_XprbUgjq805A_tZoHrVO9St4VytOmMKaVfCdiA; path=/; expires=Sun, 09-Feb-25 15:15:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=cIlDk24NddkO9tY4kicu9vo29YVg4W9bhuwzr6szBjI-1739112354742-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90f4a53c892b5514-DEL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:54,212 - openai._base_client - DEBUG - request_id: req_dd561488ae6c0dc0c06546d229e0f51a\n",
      "2025-02-09 20:15:54,219 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Act as an assistant tasked with summarizing the tables and text. Give a concise summary of the table or text. Table or text chunk: U.S. LNG Reduces Carbon Intensity of Electricity?\\n\\nStrong LNG Growth Outlook*\\n\\n1,200 800 o v, 400 0 Germany, Germany, Domestic Coal U.S. Permian LNG\\n\\n= = =\\n\\n—\\n\\nOo 2\\n\\n>40% Reduction a a in lifecycle GHG emissions when switching from domestic coal to imported LNG\\n\\n750\\n\\n>300 MTPA Suppl 500 Gar 080 < p by = S Under Construction 250 Operational 0 2022 2050\\n\\n2050\\n\\n1U.S E.l.A Power Plant Operations Report. 2IEA, Global Coal Consumption, 2000-2025. 3ICF International, Update to the Life-Cycle Analysis of GHG Emissions for US LNG Exports. ‘Source Wood Mackenzie Q4 2022.\\n\\nConocoPhillips 17\\n\\n10-Year Plan Reflects Durable Returns-Focused Value Proposition\\n\\nww\\n\\nCapital ($B)\\n\\nFCF ($B)\\n\\n12\\n\\n~$11B 2023 Capital\\n\\n9 6 3 0 2023E 2024-2028 2029-2032 Average Average\\n\\n; Production (MBOED)\\n\\n~d- 908 43% 2,000 Production CAGR 1,500 1,000 500 ° 20286 TNcrage, vNverage.\\n\\n25 $80/BBL 20 WTI Upside Sensitivity 15 10 $60 /BBL WTI Mid-Cycle 5 Planning Price 0 2023E 2024-2028 2029-2032 Average Average\\n\\n>$115B FCF\\n\\nOver the Next 10 Years at $60/BBL WTI\\n\\n~$35/BBL WTI FCF Breakeven\\n\\nAverage Over the Next 10 Years\\n\\nFree cash flow (FCF) is a non-GAAP measure defined in the Appendix.\\n\\nConocoPhillips 18'}], 'model': 'gpt-4o', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "2025-02-09 20:15:54,220 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-02-09 20:15:54,221 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:54,222 - httpcore.http11 - DEBUG - send_request_headers.complete\n",
      "2025-02-09 20:15:54,222 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:54,223 - httpcore.http11 - DEBUG - send_request_body.complete\n",
      "2025-02-09 20:15:54,223 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:55,515 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 33\n",
      "2025-02-09 20:15:56,128 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Feb 2025 14:45:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'5544'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'498'), (b'x-ratelimit-remaining-tokens', b'28815'), (b'x-ratelimit-reset-requests', b'178ms'), (b'x-ratelimit-reset-tokens', b'2.368s'), (b'x-request-id', b'req_62bd5cbb8a8d6f0f0064729ba907ba37'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.v3ujGlWYmU7qz1RKQsFFK1irYDjq5khHMfTNrZXFD8-1739112356-1.0.1.1-OCp5X9TthXNDi_DFZBnXa8uBgZ_zd0J40wofrMVCBB0MEOgc9rKmf8nBVLx7otD8S8VCf_sNC_l6VvTNAG92lQ; path=/; expires=Sun, 09-Feb-25 15:15:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=24G.MJ_JlGktApxjlh0JGl6nf.fqBqT0fm7vwwKv6LM-1739112356484-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f4a53c88f1599c-DEL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:56,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 20:15:56,131 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:56,132 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-09 20:15:56,132 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-09 20:15:56,133 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-09 20:15:56,133 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 09 Feb 2025 14:45:56 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-gccgvei9eaw4a1hksddpirf5'), ('openai-processing-ms', '5544'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '30000'), ('x-ratelimit-remaining-requests', '498'), ('x-ratelimit-remaining-tokens', '28815'), ('x-ratelimit-reset-requests', '178ms'), ('x-ratelimit-reset-tokens', '2.368s'), ('x-request-id', 'req_62bd5cbb8a8d6f0f0064729ba907ba37'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=.v3ujGlWYmU7qz1RKQsFFK1irYDjq5khHMfTNrZXFD8-1739112356-1.0.1.1-OCp5X9TthXNDi_DFZBnXa8uBgZ_zd0J40wofrMVCBB0MEOgc9rKmf8nBVLx7otD8S8VCf_sNC_l6VvTNAG92lQ; path=/; expires=Sun, 09-Feb-25 15:15:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=24G.MJ_JlGktApxjlh0JGl6nf.fqBqT0fm7vwwKv6LM-1739112356484-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90f4a53c88f1599c-DEL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:56,134 - openai._base_client - DEBUG - request_id: req_62bd5cbb8a8d6f0f0064729ba907ba37\n",
      "2025-02-09 20:15:56,433 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Feb 2025 14:45:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'2678'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'27216'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'5.566s'), (b'x-request-id', b'req_4cfee87e3e40dcaf672e440f47023e51'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f4a553e94459e2-DEL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:56,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 20:15:56,437 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:56,439 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-09 20:15:56,440 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-09 20:15:56,441 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-09 20:15:56,442 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sun, 09 Feb 2025 14:45:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-gccgvei9eaw4a1hksddpirf5', 'openai-processing-ms': '2678', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '27216', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '5.566s', 'x-request-id': 'req_4cfee87e3e40dcaf672e440f47023e51', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90f4a553e94459e2-DEL', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-02-09 20:15:56,443 - openai._base_client - DEBUG - request_id: req_4cfee87e3e40dcaf672e440f47023e51\n",
      "2025-02-09 20:15:57,442 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 33\n",
      "2025-02-09 20:15:57,713 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Feb 2025 14:45:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'3118'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'26853'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'6.292s'), (b'x-request-id', b'req_7392dc8826bc64685f531326d0559d58'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f4a55969055514-DEL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:15:57,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 20:15:57,715 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:15:57,737 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-09 20:15:57,737 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-09 20:15:57,738 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-09 20:15:57,739 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sun, 09 Feb 2025 14:45:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-gccgvei9eaw4a1hksddpirf5', 'openai-processing-ms': '3118', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '26853', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '6.292s', 'x-request-id': 'req_7392dc8826bc64685f531326d0559d58', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90f4a55969055514-DEL', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-02-09 20:15:57,739 - openai._base_client - DEBUG - request_id: req_7392dc8826bc64685f531326d0559d58\n",
      "2025-02-09 20:15:58,786 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 33\n",
      "2025-02-09 20:16:02,682 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Feb 2025 14:46:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'9584'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'27386'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'5.227s'), (b'x-request-id', b'req_db0c4ba88fecb9325007bf64968d3bb5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f4a54f997f54e8-DEL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:16:02,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 20:16:02,692 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:16:02,695 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-09 20:16:02,695 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-09 20:16:02,696 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-09 20:16:02,697 - httpcore.connection - DEBUG - close.started\n",
      "2025-02-09 20:16:02,704 - httpcore.connection - DEBUG - close.complete\n",
      "2025-02-09 20:16:02,705 - httpcore.connection - DEBUG - close.started\n",
      "2025-02-09 20:16:02,706 - httpcore.connection - DEBUG - close.complete\n",
      "2025-02-09 20:16:02,707 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sun, 09 Feb 2025 14:46:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-gccgvei9eaw4a1hksddpirf5', 'openai-processing-ms': '9584', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '27386', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '5.227s', 'x-request-id': 'req_db0c4ba88fecb9325007bf64968d3bb5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90f4a54f997f54e8-DEL', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-02-09 20:16:02,711 - openai._base_client - DEBUG - request_id: req_db0c4ba88fecb9325007bf64968d3bb5\n",
      "2025-02-09 20:16:03,055 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Feb 2025 14:46:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-gccgvei9eaw4a1hksddpirf5'), (b'openai-processing-ms', b'8950'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'27053'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'5.893s'), (b'x-request-id', b'req_1a0a6f0a75be57ed293b6332a78c3abf'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90f4a556ae7759d0-DEL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-02-09 20:16:03,057 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-09 20:16:03,059 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-09 20:16:03,061 - httpcore.http11 - DEBUG - receive_response_body.complete\n",
      "2025-02-09 20:16:03,061 - httpcore.http11 - DEBUG - response_closed.started\n",
      "2025-02-09 20:16:03,062 - httpcore.http11 - DEBUG - response_closed.complete\n",
      "2025-02-09 20:16:03,063 - httpcore.connection - DEBUG - close.started\n",
      "2025-02-09 20:16:03,064 - httpcore.connection - DEBUG - close.complete\n",
      "2025-02-09 20:16:03,064 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sun, 09 Feb 2025 14:46:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-gccgvei9eaw4a1hksddpirf5', 'openai-processing-ms': '8950', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '27053', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '5.893s', 'x-request-id': 'req_1a0a6f0a75be57ed293b6332a78c3abf', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90f4a556ae7759d0-DEL', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-02-09 20:16:03,065 - openai._base_client - DEBUG - request_id: req_1a0a6f0a75be57ed293b6332a78c3abf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 20:16:04,093 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 33\n"
     ]
    }
   ],
   "source": [
    "raw_text, text_summaries, summary_metadata = text_summarizer.generate_summary(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_metadata[0][\"uuid\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filetype': 'application/pdf',\n",
       " 'languages': ['eng'],\n",
       " 'last_modified': '2025-02-06T12:34:29',\n",
       " 'page_number': 1,\n",
       " 'orig_elements': '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',\n",
       " 'file_directory': 'backend/data/raw_pdfs',\n",
       " 'filename': '2023_removed.pdf',\n",
       " 'uuid': 'test'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bounce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
